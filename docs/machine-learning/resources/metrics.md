---
title: ML.NET metriky
description: Pochopit metriky, které se používají k vyhodnocení výkonu ML.NET modelu
ms.date: 12/17/2019
ms.openlocfilehash: 8e823fd8cc344c1b8e0ecd709b527137368cbfa0
ms.sourcegitcommit: 7588136e355e10cbc2582f389c90c127363c02a5
ms.translationtype: MT
ms.contentlocale: cs-CZ
ms.lasthandoff: 03/15/2020
ms.locfileid: "79399215"
---
# <a name="evaluate-your-mlnet-model-with-metrics"></a><span data-ttu-id="bc777-103">Vyhodnoťte svůj ML.NET model pomocí metrik</span><span class="sxs-lookup"><span data-stu-id="bc777-103">Evaluate your ML.NET model with metrics</span></span>

<span data-ttu-id="bc777-104">Seznamte se s metrikami použitými k vyhodnocení ML.NET modelu.</span><span class="sxs-lookup"><span data-stu-id="bc777-104">Understand the metrics used to evaluate an ML.NET model.</span></span>

<span data-ttu-id="bc777-105">Metriky hodnocení jsou specifické pro typ úlohy strojového učení, kterou model provádí.</span><span class="sxs-lookup"><span data-stu-id="bc777-105">Evaluation metrics are specific to the type of machine learning task that a model performs.</span></span>

<span data-ttu-id="bc777-106">Například pro úkol klasifikace je model vyhodnocen měřením, jak dobře předpovídaná kategorie odpovídá skutečné kategorii.</span><span class="sxs-lookup"><span data-stu-id="bc777-106">For example, for the classification task, the model is evaluated by measuring how well a predicted category matches the actual category.</span></span> <span data-ttu-id="bc777-107">A pro clustering hodnocení je založena na tom, jak blízko clusterované položky jsou k sobě navzájem a kolik oddělení je mezi clustery.</span><span class="sxs-lookup"><span data-stu-id="bc777-107">And for clustering, evaluation is based on how close clustered items are to each other, and how much separation there is between the clusters.</span></span>

## <a name="evaluation-metrics-for-binary-classification"></a><span data-ttu-id="bc777-108">Hodnotící metriky pro binární klasifikaci</span><span class="sxs-lookup"><span data-stu-id="bc777-108">Evaluation metrics for Binary Classification</span></span>

| <span data-ttu-id="bc777-109">Metriky</span><span class="sxs-lookup"><span data-stu-id="bc777-109">Metrics</span></span>   |      <span data-ttu-id="bc777-110">Popis</span><span class="sxs-lookup"><span data-stu-id="bc777-110">Description</span></span>      |  <span data-ttu-id="bc777-111">Hledat</span><span class="sxs-lookup"><span data-stu-id="bc777-111">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="bc777-112">**Přesnost**</span><span class="sxs-lookup"><span data-stu-id="bc777-112">**Accuracy**</span></span> |  <span data-ttu-id="bc777-113">[Přesnost](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) je podíl správných předpovědí se sadou testovacích dat.</span><span class="sxs-lookup"><span data-stu-id="bc777-113">[Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) is the proportion of correct predictions with a test data set.</span></span> <span data-ttu-id="bc777-114">Jedná se o poměr počtu správných předpovědí k celkovému počtu vstupních vzorků.</span><span class="sxs-lookup"><span data-stu-id="bc777-114">It is the ratio of number of correct predictions to the total number of input samples.</span></span> <span data-ttu-id="bc777-115">Funguje dobře, pokud existuje podobný počet vzorků, které patří do každé třídy.</span><span class="sxs-lookup"><span data-stu-id="bc777-115">It works well if there are similar number of samples belonging to each class.</span></span>| <span data-ttu-id="bc777-116">**Čím blíže k 1,00, tím lépe**.</span><span class="sxs-lookup"><span data-stu-id="bc777-116">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="bc777-117">Ale přesně 1,00 označuje problém (obvykle: label/target leakleak, over-fitting nebo testing with training data).</span><span class="sxs-lookup"><span data-stu-id="bc777-117">But exactly 1.00 indicates an issue (commonly: label/target leakage, over-fitting, or testing with training data).</span></span> <span data-ttu-id="bc777-118">Pokud jsou testovací data nevyvážená (kde většina instancí patří do jedné z tříd), datová sada je malá nebo skóre přístup 0,00 nebo 1,00, pak přesnost není ve skutečnosti zachytit účinnost třídění a je třeba zkontrolovat další metriky.</span><span class="sxs-lookup"><span data-stu-id="bc777-118">When the test data is unbalanced (where most of the instances belong to one of the classes), the dataset is small, or scores approach 0.00 or 1.00, then accuracy doesn’t really capture the effectiveness of a classifier and you need to check additional metrics.</span></span> |
| <span data-ttu-id="bc777-119">**Auc**</span><span class="sxs-lookup"><span data-stu-id="bc777-119">**AUC**</span></span> |    <span data-ttu-id="bc777-120">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) nebo *Oblast pod křivkou* měří plochu pod křivkou vytvořenou zametáním skutečné kladné míry vs. falešně pozitivní rychlost.</span><span class="sxs-lookup"><span data-stu-id="bc777-120">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) or *Area under the curve* measures the area under the curve created by sweeping the true positive rate vs. the false positive rate.</span></span>  |   <span data-ttu-id="bc777-121">**Čím blíže k 1,00, tím lépe**.</span><span class="sxs-lookup"><span data-stu-id="bc777-121">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="bc777-122">Pro přijatelný by měl být model větší než 0,50.</span><span class="sxs-lookup"><span data-stu-id="bc777-122">It should be greater than 0.50 for a model to be acceptable.</span></span> <span data-ttu-id="bc777-123">Model s AUC 0,50 nebo méně je bezcenný.</span><span class="sxs-lookup"><span data-stu-id="bc777-123">A model with AUC of 0.50 or less is worthless.</span></span> |
| <span data-ttu-id="bc777-124">**AUCPR**</span><span class="sxs-lookup"><span data-stu-id="bc777-124">**AUCPR**</span></span> | <span data-ttu-id="bc777-125">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) nebo *oblast pod křivkou precision-recall křivky*: Užitečné měřítko úspěšnosti predikce, když jsou třídy nevyvážené (vysoce zkosené datové sady).</span><span class="sxs-lookup"><span data-stu-id="bc777-125">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) or *Area under the curve of a Precision-Recall curve*: Useful measure of success of prediction when the classes are imbalanced (highly skewed datasets).</span></span> |  <span data-ttu-id="bc777-126">**Čím blíže k 1,00, tím lépe**.</span><span class="sxs-lookup"><span data-stu-id="bc777-126">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="bc777-127">Vysoké skóre téměř 1,00 ukazují, že třídění vrací přesné výsledky (vysoká přesnost), stejně jako vrácení většiny všech pozitivních výsledků (vysoké odvolání).</span><span class="sxs-lookup"><span data-stu-id="bc777-127">High scores close to 1.00 show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).</span></span> |
| <span data-ttu-id="bc777-128">**F1-skóre**</span><span class="sxs-lookup"><span data-stu-id="bc777-128">**F1-score**</span></span> | <span data-ttu-id="bc777-129">[F1 skóre](https://en.wikipedia.org/wiki/F1_score) také známé jako *vyvážené F-skóre nebo F-míra*.</span><span class="sxs-lookup"><span data-stu-id="bc777-129">[F1 score](https://en.wikipedia.org/wiki/F1_score) also known as *balanced F-score or F-measure*.</span></span> <span data-ttu-id="bc777-130">Je to harmonický průměr přesnosti a odvolání.</span><span class="sxs-lookup"><span data-stu-id="bc777-130">It's the harmonic mean of the precision and recall.</span></span> <span data-ttu-id="bc777-131">F1 Skóre je užitečné, pokud chcete najít rovnováhu mezi Precision a Recall.</span><span class="sxs-lookup"><span data-stu-id="bc777-131">F1 Score is helpful when you want to seek a balance between Precision and Recall.</span></span>| <span data-ttu-id="bc777-132">**Čím blíže k 1,00, tím lépe**.</span><span class="sxs-lookup"><span data-stu-id="bc777-132">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="bc777-133">Skóre F1 dosahuje své nejlepší hodnoty na 1,00 a nejhorší skóre na 0,00.</span><span class="sxs-lookup"><span data-stu-id="bc777-133">An F1 score reaches its best value at 1.00 and worst score at 0.00.</span></span> <span data-ttu-id="bc777-134">To vám řekne, jak přesné je váš třídění.</span><span class="sxs-lookup"><span data-stu-id="bc777-134">It tells you how precise your classifier is.</span></span> |

<span data-ttu-id="bc777-135">Další podrobnosti o binárníklasifikaci metriky přečtěte si následující články:</span><span class="sxs-lookup"><span data-stu-id="bc777-135">For further details on binary classification metrics read the following articles:</span></span>

- [<span data-ttu-id="bc777-136">Přesnost, přesnost, odvolání nebo F1?</span><span class="sxs-lookup"><span data-stu-id="bc777-136">Accuracy, Precision, Recall, or F1?</span></span>](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)
- [<span data-ttu-id="bc777-137">Binární klasifikace Metriky třídy</span><span class="sxs-lookup"><span data-stu-id="bc777-137">Binary Classification Metrics class</span></span>](xref:Microsoft.ML.Data.BinaryClassificationMetrics)
- [<span data-ttu-id="bc777-138">Vztah mezi křivkami precision-recall a ROC</span><span class="sxs-lookup"><span data-stu-id="bc777-138">The Relationship Between Precision-Recall and ROC Curves</span></span>](http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf)

## <a name="evaluation-metrics-for-multi-class-classification"></a><span data-ttu-id="bc777-139">Hodnotící metriky pro klasifikaci více tříd</span><span class="sxs-lookup"><span data-stu-id="bc777-139">Evaluation metrics for Multi-class Classification</span></span>

| <span data-ttu-id="bc777-140">Metriky</span><span class="sxs-lookup"><span data-stu-id="bc777-140">Metrics</span></span>   |      <span data-ttu-id="bc777-141">Popis</span><span class="sxs-lookup"><span data-stu-id="bc777-141">Description</span></span>      |  <span data-ttu-id="bc777-142">Hledat</span><span class="sxs-lookup"><span data-stu-id="bc777-142">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="bc777-143">**Mikropřesnost**</span><span class="sxs-lookup"><span data-stu-id="bc777-143">**Micro-Accuracy**</span></span> |  <span data-ttu-id="bc777-144">[Mikroprůměrná přesnost](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) agreguje příspěvky všech tříd pro výpočet průměrné metriky.</span><span class="sxs-lookup"><span data-stu-id="bc777-144">[Micro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) aggregates the contributions of all classes to compute the average metric.</span></span> <span data-ttu-id="bc777-145">Jedná se o zlomek správně předpovídaných instancí.</span><span class="sxs-lookup"><span data-stu-id="bc777-145">It is the fraction of instances predicted correctly.</span></span> <span data-ttu-id="bc777-146">Mikro-průměr nebere v úvahu členství ve třídě.</span><span class="sxs-lookup"><span data-stu-id="bc777-146">The micro-average does not take class membership into account.</span></span> <span data-ttu-id="bc777-147">V podstatě každý pár třídy vzorku přispívá stejně k metrike přesnosti.</span><span class="sxs-lookup"><span data-stu-id="bc777-147">Basically, every sample-class pair contributes equally to the accuracy metric.</span></span> | <span data-ttu-id="bc777-148">**Čím blíže k 1,00, tím lépe**.</span><span class="sxs-lookup"><span data-stu-id="bc777-148">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="bc777-149">Při vícestupňové klasifikaci je mikropřesnost vhodnější než makropřesnost, pokud máte podezření, že může existovat nerovnováha třídy (tj.</span><span class="sxs-lookup"><span data-stu-id="bc777-149">In a multi-class classification task, micro-accuracy is preferable over macro-accuracy if you suspect there might be class imbalance (i.e</span></span> <span data-ttu-id="bc777-150">můžete mít mnohem více příkladů jedné třídy než jiných tříd).</span><span class="sxs-lookup"><span data-stu-id="bc777-150">you may have many more examples of one class than of other classes).</span></span>|
| <span data-ttu-id="bc777-151">**Makropřesnost**</span><span class="sxs-lookup"><span data-stu-id="bc777-151">**Macro-Accuracy**</span></span> | <span data-ttu-id="bc777-152">[Makroprůměrná přesnost](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) je průměrná přesnost na úrovni třídy.</span><span class="sxs-lookup"><span data-stu-id="bc777-152">[Macro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) is the average accuracy at the class level.</span></span> <span data-ttu-id="bc777-153">Přesnost pro každou třídu je vypočítána a přesnost maker je průměr těchto přesností.</span><span class="sxs-lookup"><span data-stu-id="bc777-153">The accuracy for each class is computed and the macro-accuracy is the average of these accuracies.</span></span> <span data-ttu-id="bc777-154">V podstatě každá třída přispívá stejně k metrike přesnosti.</span><span class="sxs-lookup"><span data-stu-id="bc777-154">Basically, every class contributes equally to the accuracy metric.</span></span> <span data-ttu-id="bc777-155">Menšinové třídy mají stejnou váhu jako větší třídy.</span><span class="sxs-lookup"><span data-stu-id="bc777-155">Minority classes are given equal weight as the larger classes.</span></span> <span data-ttu-id="bc777-156">Makroprůměrná metrika poskytuje stejnou váhu každé třídě bez ohledu na to, kolik instancí z této třídy datová sada obsahuje.</span><span class="sxs-lookup"><span data-stu-id="bc777-156">The macro-average metric gives the same weight to each class, no matter how many instances from that class the dataset contains.</span></span> |  <span data-ttu-id="bc777-157">**Čím blíže k 1,00, tím lépe**.</span><span class="sxs-lookup"><span data-stu-id="bc777-157">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="bc777-158">Vypočítá metriku nezávisle pro každou třídu a pak vezme průměr (tedy zacházet se všemi třídami stejně)</span><span class="sxs-lookup"><span data-stu-id="bc777-158">It computes the metric independently for each class and then takes the average (hence treating all classes equally)</span></span> |
| <span data-ttu-id="bc777-159">**Ztráta protokolu**</span><span class="sxs-lookup"><span data-stu-id="bc777-159">**Log-loss**</span></span>| <span data-ttu-id="bc777-160">[Logaritmická ztráta](http://wiki.fast.ai/index.php/Log_Loss) měří výkon klasifikačního modelu, kde vstup předpovědi je hodnota pravděpodobnosti mezi 0,00 a 1,00.</span><span class="sxs-lookup"><span data-stu-id="bc777-160">[Logarithmic loss](http://wiki.fast.ai/index.php/Log_Loss) measures the performance of a classification model where the prediction input is a probability value between 0.00 and 1.00.</span></span> <span data-ttu-id="bc777-161">Ztráta protokolu se zvyšuje, protože předpokládaná pravděpodobnost se liší od skutečného popisku.</span><span class="sxs-lookup"><span data-stu-id="bc777-161">Log-loss increases as the predicted probability diverges from the actual label.</span></span> | <span data-ttu-id="bc777-162">**Čím blíže k 0,00, tím lépe**.</span><span class="sxs-lookup"><span data-stu-id="bc777-162">**The closer to 0.00, the better**.</span></span> <span data-ttu-id="bc777-163">Perfektní model by měl log-loss 0,00.</span><span class="sxs-lookup"><span data-stu-id="bc777-163">A perfect model would have a log-loss of 0.00.</span></span> <span data-ttu-id="bc777-164">Cílem našich modelů strojového učení je minimalizovat tuto hodnotu.</span><span class="sxs-lookup"><span data-stu-id="bc777-164">The goal of our machine learning models is to minimize this value.</span></span>|
| <span data-ttu-id="bc777-165">**Snížení ztráty protokolu**</span><span class="sxs-lookup"><span data-stu-id="bc777-165">**Log-Loss Reduction**</span></span> | <span data-ttu-id="bc777-166">[Logaritmické snížení ztráty](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) lze interpretovat jako výhodu třídění přes náhodné předpověď.</span><span class="sxs-lookup"><span data-stu-id="bc777-166">[Logarithmic loss reduction](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) can be interpreted as the advantage of the classifier over a random prediction.</span></span>| <span data-ttu-id="bc777-167">**V rozsahu od -inf a 1,00, kde 1,00 je perfektní předpovědi a 0,00 označuje střední předpovědi**.</span><span class="sxs-lookup"><span data-stu-id="bc777-167">**Ranges from -inf and 1.00, where 1.00 is perfect predictions and 0.00 indicates mean predictions**.</span></span> <span data-ttu-id="bc777-168">Například pokud se hodnota rovná 0,20, může být interpretována jako "pravděpodobnost správné předpovědi je o 20 % lepší než náhodné odhadování"</span><span class="sxs-lookup"><span data-stu-id="bc777-168">For example, if the value equals 0.20, it can be interpreted as "the probability of a correct prediction is 20% better than random guessing"</span></span>|

<span data-ttu-id="bc777-169">Mikropřesnost je obecně lépe v souladu s obchodními potřebami předpovědí ML.</span><span class="sxs-lookup"><span data-stu-id="bc777-169">Micro-accuracy is generally better aligned with the business needs of ML predictions.</span></span> <span data-ttu-id="bc777-170">Pokud chcete vybrat jednu metriku pro výběr kvality úlohy klasifikace více tříd, měla by být obvykle mikropřesnost.</span><span class="sxs-lookup"><span data-stu-id="bc777-170">If you want to select a single metric for choosing the quality of a multiclass classification task, it should usually be micro-accuracy.</span></span>

<span data-ttu-id="bc777-171">Příklad pro úkol klasifikace lístků podpory: (mapuje příchozí vstupenky podpůrným týmům)</span><span class="sxs-lookup"><span data-stu-id="bc777-171">Example, for a support ticket classification task: (maps incoming tickets to support teams)</span></span>

- <span data-ttu-id="bc777-172">Mikropřesnost - jak často se příchozí jízdenka dostane do správného týmu?</span><span class="sxs-lookup"><span data-stu-id="bc777-172">Micro-accuracy -- how often does an incoming ticket get classified to the right team?</span></span>
- <span data-ttu-id="bc777-173">Makro-přesnost - pro průměrný tým, jak často je příchozí lístek správný pro jejich tým?</span><span class="sxs-lookup"><span data-stu-id="bc777-173">Macro-accuracy -- for an average team, how often is an incoming ticket correct for their team?</span></span>

<span data-ttu-id="bc777-174">Makropřesnost má v tomto příkladu nadváhu malých týmů. malý tým, který dostane pouze 10 vstupenek ročně se počítá stejně jako velký tým s 10k vstupenky za rok.</span><span class="sxs-lookup"><span data-stu-id="bc777-174">Macro-accuracy overweights small teams in this example; a small team that gets only 10 tickets per year counts as much as a large team with 10k tickets per year.</span></span> <span data-ttu-id="bc777-175">Mikro-přesnost v tomto případě koreluje lépe s obchodní potřebou, "kolik času / peněz může společnost ušetřit automatizací mého procesu směrování vstupenek".</span><span class="sxs-lookup"><span data-stu-id="bc777-175">Micro-accuracy in this case correlates better with the business need of, "how much time/money can the company save by automating my ticket routing process".</span></span>

<span data-ttu-id="bc777-176">Další podrobnosti o metrikách klasifikace více tříd načtou následující články:</span><span class="sxs-lookup"><span data-stu-id="bc777-176">For further details on multi-class classification metrics read the following articles:</span></span>

- [<span data-ttu-id="bc777-177">Mikroprůměr přesnosti, odvolání a f-skóre</span><span class="sxs-lookup"><span data-stu-id="bc777-177">Micro- and Macro-average of Precision, Recall, and F-Score</span></span>](https://rushdishams.blogspot.com/2011/08/micro-and-macro-average-of-precision.html)
- [<span data-ttu-id="bc777-178">Klasifikace více tříd s nevyváženou datovou sadou</span><span class="sxs-lookup"><span data-stu-id="bc777-178">Multiclass Classification with Imbalanced Dataset</span></span>](https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a)

## <a name="evaluation-metrics-for-regression-and-recommendation"></a><span data-ttu-id="bc777-179">Hodnotící metriky pro regresi a doporučení</span><span class="sxs-lookup"><span data-stu-id="bc777-179">Evaluation metrics for Regression and Recommendation</span></span>

<span data-ttu-id="bc777-180">Regrese a doporučení úkoly předpovědět číslo.</span><span class="sxs-lookup"><span data-stu-id="bc777-180">Both the regression and recommendation tasks predict a number.</span></span> <span data-ttu-id="bc777-181">V případě regrese může být číslo libovolnou výstupní vlastností, která je ovlivněna vstupními vlastnostmi.</span><span class="sxs-lookup"><span data-stu-id="bc777-181">In the case of regression, the number can be any output property that is influenced by the input properties.</span></span> <span data-ttu-id="bc777-182">Pro doporučení je číslo obvykle hodnota hodnocení (například mezi 1 a 5) nebo doporučení ano/ne (reprezentované 1 a 0).</span><span class="sxs-lookup"><span data-stu-id="bc777-182">For recommendation, the number is usually a rating value (between 1 and 5 for example), or a yes/no recommendation (represented by 1 and 0 respectively).</span></span>

| <span data-ttu-id="bc777-183">Metrika</span><span class="sxs-lookup"><span data-stu-id="bc777-183">Metric</span></span>   |      <span data-ttu-id="bc777-184">Popis</span><span class="sxs-lookup"><span data-stu-id="bc777-184">Description</span></span>      |  <span data-ttu-id="bc777-185">Hledat</span><span class="sxs-lookup"><span data-stu-id="bc777-185">Look for</span></span> |
|----------|-----------------------|-----------|
| <span data-ttu-id="bc777-186">**R-na druhou**</span><span class="sxs-lookup"><span data-stu-id="bc777-186">**R-Squared**</span></span> |  <span data-ttu-id="bc777-187">[R-kvadrát (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination)nebo *koeficient stanovení* představuje prediktivní sílu modelu jako hodnotu mezi -inf a 1,00.</span><span class="sxs-lookup"><span data-stu-id="bc777-187">[R-squared (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination), or *Coefficient of determination* represents the predictive power of the model as a value between -inf and 1.00.</span></span> <span data-ttu-id="bc777-188">1.00 znamená, že je perfektní fit, a fit může být libovolně špatná, takže skóre může být negativní.</span><span class="sxs-lookup"><span data-stu-id="bc777-188">1.00 means there is a perfect fit, and the fit can be arbitrarily poor so the scores can be negative.</span></span> <span data-ttu-id="bc777-189">Skóre 0,00 znamená, že model je hádat očekávanou hodnotu pro popisek.</span><span class="sxs-lookup"><span data-stu-id="bc777-189">A score of 0.00 means the model is guessing the expected value for the label.</span></span> <span data-ttu-id="bc777-190">R2 měří, jak blízko jsou hodnoty skutečných testovacích dat předpovídaným hodnotám.</span><span class="sxs-lookup"><span data-stu-id="bc777-190">R2 measures how close the actual test data values are to the predicted values.</span></span> | <span data-ttu-id="bc777-191">**Čím blíže k 1,00, tím lepší kvalita**.</span><span class="sxs-lookup"><span data-stu-id="bc777-191">**The closer to 1.00, the better quality**.</span></span> <span data-ttu-id="bc777-192">Někdy však nízké hodnoty na druhou R (například 0,50) může být zcela normální nebo dost dobré pro váš scénář a vysoké hodnoty na druhou R nejsou vždy dobré a podezřelé.</span><span class="sxs-lookup"><span data-stu-id="bc777-192">However, sometimes low R-squared values (such as 0.50) can be entirely normal or good enough for your scenario and high R-squared values are not always good and be suspicious.</span></span> |
| <span data-ttu-id="bc777-193">**Absolutní ztráta**</span><span class="sxs-lookup"><span data-stu-id="bc777-193">**Absolute-loss**</span></span> |  <span data-ttu-id="bc777-194">[Absolutní ztráta](https://en.wikipedia.org/wiki/Mean_absolute_error) nebo *střední absolutní chyba (MAE)* měří, jak blízko jsou předpovědi ke skutečným výsledkům.</span><span class="sxs-lookup"><span data-stu-id="bc777-194">[Absolute-loss](https://en.wikipedia.org/wiki/Mean_absolute_error) or *Mean absolute error (MAE)* measures how close the predictions are to the actual outcomes.</span></span> <span data-ttu-id="bc777-195">Jedná se o průměr všech chyb modelu, kde chyba modelu je absolutní vzdálenost mezi předpokládanou hodnotou popisku a správnou hodnotou popisku.</span><span class="sxs-lookup"><span data-stu-id="bc777-195">It is the average of all the model errors, where model error is the absolute distance between the predicted label value and the correct label value.</span></span> <span data-ttu-id="bc777-196">Tato chyba předpověď se vypočítá pro každý záznam testovací datové sady.</span><span class="sxs-lookup"><span data-stu-id="bc777-196">This prediction error is calculated for each record of the test data set.</span></span> <span data-ttu-id="bc777-197">Nakonec se vypočítá střední hodnota pro všechny zaznamenané absolutní chyby.</span><span class="sxs-lookup"><span data-stu-id="bc777-197">Finally, the mean value is calculated for all recorded absolute errors.</span></span>| <span data-ttu-id="bc777-198">**Čím blíže k 0,00, tím lepší kvalitu.**</span><span class="sxs-lookup"><span data-stu-id="bc777-198">**The closer to 0.00, the better quality.**</span></span> <span data-ttu-id="bc777-199">Průměrná absolutní chyba používá stejné měřítko jako měřená data (není normalizována na konkrétní rozsah).</span><span class="sxs-lookup"><span data-stu-id="bc777-199">The mean absolute error uses the same scale as the data being measured (is not normalized to specific range).</span></span> <span data-ttu-id="bc777-200">Absolutní ztráta, kvadrátální ztráta a ztráta RMS lze použít pouze k porovnání mezi modely pro stejnou datovou sadu nebo datovou sadu s podobným rozložením hodnoty popisku.</span><span class="sxs-lookup"><span data-stu-id="bc777-200">Absolute-loss, Squared-loss, and RMS-loss can only be used to make comparisons between models for the same dataset or dataset with a similar label value distribution.</span></span> |
| <span data-ttu-id="bc777-201">**Kvadrač-ztráta**</span><span class="sxs-lookup"><span data-stu-id="bc777-201">**Squared-loss**</span></span> |  <span data-ttu-id="bc777-202">[Kvadratická nebo](https://en.wikipedia.org/wiki/Mean_squared_error) *střední kvadratická chyba (MSE)*, také nazývaná *střední kvadratická odchylka (MSD),* vám řekne, jak blízko je regresní čára k sadě hodnot testovacích dat tím, že vezme vzdálenosti od bodů k regresní čáře (tyto vzdálenosti jsou chyby E) a kvadraturu je.</span><span class="sxs-lookup"><span data-stu-id="bc777-202">[Squared-loss](https://en.wikipedia.org/wiki/Mean_squared_error) or *Mean Squared Error (MSE)*, also called *Mean Squared Deviation (MSD)*, tells you how close a regression line is to a set of test data values by taking the distances from the points to the regression line (these distances are the errors E) and squaring them.</span></span> <span data-ttu-id="bc777-203">Kvadratura dává větší váhu větším rozdílům.</span><span class="sxs-lookup"><span data-stu-id="bc777-203">The squaring gives more weight to larger differences.</span></span> | <span data-ttu-id="bc777-204">Je vždy nezáporná a **hodnoty blíže k 0,00 jsou lepší**.</span><span class="sxs-lookup"><span data-stu-id="bc777-204">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="bc777-205">V závislosti na vašich datech může být nemožné získat velmi malou hodnotu pro střední kvadratorovou chybu.</span><span class="sxs-lookup"><span data-stu-id="bc777-205">Depending on your data, it may be impossible to get a very small value for the mean squared error.</span></span>|
| <span data-ttu-id="bc777-206">**RMS-ztráta**</span><span class="sxs-lookup"><span data-stu-id="bc777-206">**RMS-loss**</span></span> |  <span data-ttu-id="bc777-207">[RMS-loss](https://en.wikipedia.org/wiki/Root-mean-square_deviation) nebo *Root Mean SquareD Error (RMSE)* (také nazývaný *Kořenová střední kvadratická odchylka, RMSD*), měří rozdíl mezi hodnotami předpovězenými modelem a hodnotami pozorovanými z prostředí, které je modelováno.</span><span class="sxs-lookup"><span data-stu-id="bc777-207">[RMS-loss](https://en.wikipedia.org/wiki/Root-mean-square_deviation) or *Root Mean Squared Error (RMSE)* (also called *Root Mean Square Deviation, RMSD*), measures the difference between values predicted by a model and the values observed from the environment that is being modeled.</span></span> <span data-ttu-id="bc777-208">RMS-ztráta je druhá odmocnina squared-ztráta a má stejné jednotky jako štítek, podobně jako absolutní-ztráta i když dává větší váhu větší rozdíly.</span><span class="sxs-lookup"><span data-stu-id="bc777-208">RMS-loss is the square root of Squared-loss and has the same units as the label, similar to the absolute-loss though giving more weight to larger differences.</span></span> <span data-ttu-id="bc777-209">Střední kvadratická chyba kořene se běžně používá v klimatologii, prognózách a regresní analýze k ověření experimentálních výsledků.</span><span class="sxs-lookup"><span data-stu-id="bc777-209">Root mean square error is commonly used in climatology, forecasting, and regression analysis to verify experimental results.</span></span> | <span data-ttu-id="bc777-210">Je vždy nezáporná a **hodnoty blíže k 0,00 jsou lepší**.</span><span class="sxs-lookup"><span data-stu-id="bc777-210">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="bc777-211">RMSD je míra přesnosti, porovnat chyby prognózy různých modelů pro konkrétní datové sady a nikoli mezi datovými sadami, protože je závislé na měřítku.</span><span class="sxs-lookup"><span data-stu-id="bc777-211">RMSD is a measure of accuracy, to compare forecasting errors of different models for a particular dataset and not between datasets, as it is scale-dependent.</span></span>|

<span data-ttu-id="bc777-212">Další podrobnosti o regresní metriky, přečtěte si následující články:</span><span class="sxs-lookup"><span data-stu-id="bc777-212">For further details on regression metrics, read the following articles:</span></span>

- [<span data-ttu-id="bc777-213">Regresní analýza: Jak interpretuji R-kvadratou a posoudit dobrotu fit?</span><span class="sxs-lookup"><span data-stu-id="bc777-213">Regression Analysis: How Do I Interpret R-squared and Assess the Goodness-of-Fit?</span></span>](https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)
- [<span data-ttu-id="bc777-214">Jak interpretovat R-kvadratý v regresní analýze</span><span class="sxs-lookup"><span data-stu-id="bc777-214">How To Interpret R-squared in Regression Analysis</span></span>](https://statisticsbyjim.com/regression/interpret-r-squared-regression)
- [<span data-ttu-id="bc777-215">R-kvadrát definice</span><span class="sxs-lookup"><span data-stu-id="bc777-215">R-Squared Definition</span></span>](https://www.investopedia.com/terms/r/r-squared.asp)
- [<span data-ttu-id="bc777-216">Definice střední kvadraté chyby</span><span class="sxs-lookup"><span data-stu-id="bc777-216">Mean Squared Error Definition</span></span>](https://www.statisticshowto.datasciencecentral.com/mean-squared-error/)
- [<span data-ttu-id="bc777-217">Co jsou střední kvadratří chyba a střední kvadratická chyba kořenového adresáře?</span><span class="sxs-lookup"><span data-stu-id="bc777-217">What are Mean Squared Error and Root Mean Squared Error?</span></span>](https://www.vernier.com/til/1014/)

## <a name="evaluation-metrics-for-clustering"></a><span data-ttu-id="bc777-218">Metriky hodnocení clusteringu</span><span class="sxs-lookup"><span data-stu-id="bc777-218">Evaluation metrics for Clustering</span></span>

| <span data-ttu-id="bc777-219">Metrika</span><span class="sxs-lookup"><span data-stu-id="bc777-219">Metric</span></span>   |      <span data-ttu-id="bc777-220">Popis</span><span class="sxs-lookup"><span data-stu-id="bc777-220">Description</span></span>      |  <span data-ttu-id="bc777-221">Hledat</span><span class="sxs-lookup"><span data-stu-id="bc777-221">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="bc777-222">**Průměrná vzdálenost**</span><span class="sxs-lookup"><span data-stu-id="bc777-222">**Average Distance**</span></span>|<span data-ttu-id="bc777-223">Průměr vzdálenosti mezi datovými body a středem přiřazeného clusteru.</span><span class="sxs-lookup"><span data-stu-id="bc777-223">Average of the distance between data points and the center of their assigned cluster.</span></span> <span data-ttu-id="bc777-224">Průměrná vzdálenost je mírou blízkosti datových bodů k centroidům clusteru.</span><span class="sxs-lookup"><span data-stu-id="bc777-224">The average distance is a measure of proximity of the data points to cluster centroids.</span></span> <span data-ttu-id="bc777-225">Je to míra toho, jak 'těsný' cluster je.</span><span class="sxs-lookup"><span data-stu-id="bc777-225">It's a measure of how 'tight' the cluster is.</span></span>|<span data-ttu-id="bc777-226">Hodnoty blíže k **0** jsou lepší.</span><span class="sxs-lookup"><span data-stu-id="bc777-226">Values closer to **0** are better.</span></span> <span data-ttu-id="bc777-227">Čím blíže k nule je průměrná vzdálenost, tím více seskupených dat je.</span><span class="sxs-lookup"><span data-stu-id="bc777-227">The closer to zero the average distance is, the more clustered the data is.</span></span> <span data-ttu-id="bc777-228">Všimněte si však, že tato metrika se sníží, pokud se zvýší počet clusterů a v extrémním případě (kde každý odlišný datový bod je vlastní cluster) se bude rovnat nule.</span><span class="sxs-lookup"><span data-stu-id="bc777-228">Note though, that this metric will decrease if the number of clusters is increased, and in the extreme case (where each distinct data point is its own cluster) it will be equal to zero.</span></span>
|<span data-ttu-id="bc777-229">**Davies Bouldin Index**</span><span class="sxs-lookup"><span data-stu-id="bc777-229">**Davies Bouldin Index**</span></span>|<span data-ttu-id="bc777-230">Průměrný poměr vzdáleností v rámci clusteru k mezikupami.</span><span class="sxs-lookup"><span data-stu-id="bc777-230">The average ratio of within-cluster distances to between-cluster distances.</span></span> <span data-ttu-id="bc777-231">Čím těsnější cluster u ta je, tím nižší je tato hodnota.</span><span class="sxs-lookup"><span data-stu-id="bc777-231">The tighter the cluster, and the further apart the clusters are, the lower this value is.</span></span>|<span data-ttu-id="bc777-232">Hodnoty blíže k **0** jsou lepší.</span><span class="sxs-lookup"><span data-stu-id="bc777-232">Values closer to **0** are better.</span></span> <span data-ttu-id="bc777-233">Clustery, které jsou dále od sebe a méně rozptýlené bude mít za následek lepší skóre.</span><span class="sxs-lookup"><span data-stu-id="bc777-233">Clusters that are farther apart and less dispersed will result in a better score.</span></span>|
|<span data-ttu-id="bc777-234">**Normalizované vzájemné informace**</span><span class="sxs-lookup"><span data-stu-id="bc777-234">**Normalized Mutual Information**</span></span>|<span data-ttu-id="bc777-235">Lze použít, když trénovací data použitá k trénování modelu clusteringu také přichází s popisky pravdy země (to znamená, že pod dohledem clustering).</span><span class="sxs-lookup"><span data-stu-id="bc777-235">Can be used when the training data used to train the clustering model also comes with ground truth labels (that is, supervised clustering).</span></span> <span data-ttu-id="bc777-236">Metrika Normalizované vzájemné informace měří, zda se podobné datové body přiřadí ke stejnému clusteru a nesourodé datové body se přiřadí do různých clusterů.</span><span class="sxs-lookup"><span data-stu-id="bc777-236">The Normalized Mutual Information metric measures whether similar data points get assigned to the same cluster and disparate data points get assigned to different clusters.</span></span> <span data-ttu-id="bc777-237">Normalizované vzájemné informace je hodnota mezi 0 a 1</span><span class="sxs-lookup"><span data-stu-id="bc777-237">Normalized mutual information is a value between 0 and 1</span></span>|<span data-ttu-id="bc777-238">Hodnoty blíže k **1** jsou lepší</span><span class="sxs-lookup"><span data-stu-id="bc777-238">Values closer to **1** are better</span></span>|

## <a name="evaluation-metrics-for-ranking"></a><span data-ttu-id="bc777-239">Hodnotící metriky pro hodnocení</span><span class="sxs-lookup"><span data-stu-id="bc777-239">Evaluation metrics for Ranking</span></span>

| <span data-ttu-id="bc777-240">Metrika</span><span class="sxs-lookup"><span data-stu-id="bc777-240">Metric</span></span>   |      <span data-ttu-id="bc777-241">Popis</span><span class="sxs-lookup"><span data-stu-id="bc777-241">Description</span></span>      |  <span data-ttu-id="bc777-242">Hledat</span><span class="sxs-lookup"><span data-stu-id="bc777-242">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="bc777-243">**Diskontované kumulativní zisky**</span><span class="sxs-lookup"><span data-stu-id="bc777-243">**Discounted Cumulative Gains**</span></span>|<span data-ttu-id="bc777-244">Diskontovaný kumulativní zisk (DCG) je měřítkem kvality hodnocení.</span><span class="sxs-lookup"><span data-stu-id="bc777-244">Discounted cumulative gain (DCG) is a measure of ranking quality.</span></span> <span data-ttu-id="bc777-245">Je odvozen ze dvou předpokladů.</span><span class="sxs-lookup"><span data-stu-id="bc777-245">It is derived from two assumptions.</span></span> <span data-ttu-id="bc777-246">První: Vysoce relevantní položky jsou užitečnější, když se objevují vyšší v pořadí.</span><span class="sxs-lookup"><span data-stu-id="bc777-246">One: Highly relevant items are more useful when appearing higher in ranking order.</span></span> <span data-ttu-id="bc777-247">Za druhé: Užitečnost sleduje relevanci, která je, čím vyšší je relevance, tím užitečnější je položka.</span><span class="sxs-lookup"><span data-stu-id="bc777-247">Two: Usefulness tracks relevance that is, the higher the relevance, the more useful an item.</span></span> <span data-ttu-id="bc777-248">Diskontovaný kumulativní zisk se vypočítá pro konkrétní pozici v pořadí.</span><span class="sxs-lookup"><span data-stu-id="bc777-248">Discounted cumulative gain is calculated for a particular position in the ranking order.</span></span> <span data-ttu-id="bc777-249">Shrnuje klasifikaci relevance dělenou logaritmem žebříčku indexu až do pozice zájmu.</span><span class="sxs-lookup"><span data-stu-id="bc777-249">It sums the relevance grading divided by the logarithm of the ranking index up to the position of interest.</span></span> <span data-ttu-id="bc777-250">Vypočítá se pomocí $\sum_{i=0}^{p} \frac {rel_i} {\log_{e}{i+1}}$ Stupně relevance jsou k dispozici algoritmu hodnocení školení jako pozemní popisky pravdy.</span><span class="sxs-lookup"><span data-stu-id="bc777-250">It is calculated using $\sum_{i=0}^{p} \frac {rel_i} {\log_{e}{i+1}}$ Relevance gradings are provided to a ranking training algorithm as ground truth labels.</span></span> <span data-ttu-id="bc777-251">Pro každou pozici v tabulce pořadí je uvedena jedna hodnota DCG, proto je uveden název Diskontované kumulativní **zisky**.</span><span class="sxs-lookup"><span data-stu-id="bc777-251">One DCG value is provided for each position in the ranking table, hence the name Discounted Cumulative **Gains**.</span></span> |<span data-ttu-id="bc777-252">**Vyšší hodnoty jsou lepší**</span><span class="sxs-lookup"><span data-stu-id="bc777-252">**Higher values are better**</span></span>|
|<span data-ttu-id="bc777-253">**Normalizované diskontované kumulativní zisky**</span><span class="sxs-lookup"><span data-stu-id="bc777-253">**Normalized Discounted Cumulative Gains**</span></span>|<span data-ttu-id="bc777-254">Normalizace DCG umožňuje porovnat metriku pro pořadníky různých délek</span><span class="sxs-lookup"><span data-stu-id="bc777-254">Normalizing DCG allows the metric to be compared for ranking lists of different lengths</span></span>|<span data-ttu-id="bc777-255">**Hodnoty blíže k 1 jsou lepší**</span><span class="sxs-lookup"><span data-stu-id="bc777-255">**Values closer to 1 are better**</span></span>|

## <a name="evaluation-metrics-for-anomaly-detection"></a><span data-ttu-id="bc777-256">Metriky vyhodnocení pro detekci anomálií</span><span class="sxs-lookup"><span data-stu-id="bc777-256">Evaluation metrics for Anomaly Detection</span></span>

| <span data-ttu-id="bc777-257">Metrika</span><span class="sxs-lookup"><span data-stu-id="bc777-257">Metric</span></span>   |      <span data-ttu-id="bc777-258">Popis</span><span class="sxs-lookup"><span data-stu-id="bc777-258">Description</span></span>      |  <span data-ttu-id="bc777-259">Hledat</span><span class="sxs-lookup"><span data-stu-id="bc777-259">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="bc777-260">**Plocha pod křivkou ROC**</span><span class="sxs-lookup"><span data-stu-id="bc777-260">**Area Under ROC Curve**</span></span>|<span data-ttu-id="bc777-261">Plocha pod křivkou operátora přijímače měří, jak dobře model odděluje neobvyklé a obvyklé datové body.</span><span class="sxs-lookup"><span data-stu-id="bc777-261">Area under the receiver operator curve measures how well the model separates anomalous and usual data points.</span></span>|<span data-ttu-id="bc777-262">**Hodnoty blíže k 1 jsou lepší**.</span><span class="sxs-lookup"><span data-stu-id="bc777-262">**Values closer to 1 are better**.</span></span> <span data-ttu-id="bc777-263">Účinnost modelu demonstrují pouze hodnoty větší než 0,5.</span><span class="sxs-lookup"><span data-stu-id="bc777-263">Only values greater than 0.5 demonstrate effectiveness of the model.</span></span> <span data-ttu-id="bc777-264">Hodnoty 0,5 nebo nižší označují, že model není o nic lepší než náhodné přidělování vstupů do neobvyklých a obvyklých kategorií</span><span class="sxs-lookup"><span data-stu-id="bc777-264">Values of 0.5 or below indicate that the model is no better than randomly allocating the inputs to anomalous and usual categories</span></span>|
|<span data-ttu-id="bc777-265">**Míra detekce při falešně pozitivním počtu**</span><span class="sxs-lookup"><span data-stu-id="bc777-265">**Detection Rate At False Positive Count**</span></span>|<span data-ttu-id="bc777-266">Míra detekce při falešně pozitivním počtu je poměr počtu správně identifikovaných anomálií k celkovému počtu anomálií v testovací sadě indexovaných jednotlivými falešně pozitivními.</span><span class="sxs-lookup"><span data-stu-id="bc777-266">Detection rate at false positive count is the ratio of the number of correctly identified anomalies to the total number of anomalies in a test set, indexed by each false positive.</span></span> <span data-ttu-id="bc777-267">To znamená, že je hodnota pro zjišťování rychlost při falešně pozitivní počet pro každou falešně pozitivní položku.</span><span class="sxs-lookup"><span data-stu-id="bc777-267">That is, there is a value for detection rate at false positive count for each false positive item.</span></span>|<span data-ttu-id="bc777-268">**Hodnoty blíže k 1 jsou lepší**.</span><span class="sxs-lookup"><span data-stu-id="bc777-268">**Values closer to 1 are better**.</span></span> <span data-ttu-id="bc777-269">Pokud nejsou k dispozici žádné falešně pozitivní výsledky, je tato hodnota 1</span><span class="sxs-lookup"><span data-stu-id="bc777-269">If there are no false positives, then this value is 1</span></span>|
